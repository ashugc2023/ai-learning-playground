{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 001: Creator Content Engine (Hooks + Captions + Hashtags)\n",
        "\n",
        "## What you'll build\n",
        "A simple **creator/marketer content pack generator** that turns one idea into:\n",
        "- **10 hooks** (short-video openers)\n",
        "- **10 captions** (platform-ready)\n",
        "- **15 hashtags** (relevant + safe)\n",
        "- **1 video angle summary** (what to show visually)\n",
        "\n",
        "You can run this notebook:\n",
        "- In **Google Colab** (fastest)\n",
        "- Locally in **JupyterLab**\n",
        "\n",
        "## Providers supported\n",
        "- **OpenAI** (API key required)\n",
        "- **Gemini** (API key required)\n",
        "- **Ollama** (local model, no key)\n",
        "\n",
        "Security note: API keys are secrets. Do not paste them into cells as plain text. We use hidden input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Privacy Note\n",
        "This notebook does not track you.\n",
        "Links are counted anonymously to understand what content is useful.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Runtime check: Colab vs Local\n",
        "This helps us choose friendlier defaults.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Install dependencies\n",
        "If running locally, you can also install via `pip install -r requirements.txt`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Choose your provider\n",
        "Set `PROVIDER` to one of:\n",
        "- `\"openai\"`\n",
        "- `\"gemini\"`\n",
        "- `\"ollama\"`\n",
        "\n",
        "Defaults:\n",
        "- If you have an API key, start with OpenAI or Gemini.\n",
        "- If you want free local inference, use Ollama (requires local install).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "print('‚úì Running in Google Colab' if IN_COLAB else '‚úì Running locally (Jupyter)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Secure API key entry (hidden)\n",
        "We use hidden prompts so the key is not displayed.\n",
        "\n",
        "- OpenAI uses `OPENAI_API_KEY`.\n",
        "- Gemini uses `GEMINI_API_KEY`.\n",
        "- Ollama needs no key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def pip_install(pkgs: str) -> None:\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', '-U'] + pkgs.split())\n",
        "\n",
        "# Core utilities\n",
        "pip_install('requests')\n",
        "\n",
        "# Provider SDKs (install both; we will only use the one you select)\n",
        "pip_install('openai')\n",
        "pip_install('google-genai')\n",
        "\n",
        "print('‚úì Dependencies installed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Unified LLM call helper\n",
        "This gives us one function: `llm(prompt)` regardless of provider.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROVIDER = 'openai'  # 'openai' | 'gemini' | 'ollama'\n",
        "\n",
        "# Model defaults (you can change these)\n",
        "OPENAI_MODEL = 'gpt-4.1-mini'\n",
        "GEMINI_MODEL = 'gemini-2.0-flash'\n",
        "OLLAMA_MODEL = 'llama3.1'  # example; must exist locally\n",
        "\n",
        "print('‚úì Provider:', PROVIDER)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Connection test\n",
        "If this succeeds, your provider is set up correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "def ensure_key(env_name: str) -> None:\n",
        "    if os.getenv(env_name):\n",
        "        print(f'‚úì {env_name} is set (hidden)')\n",
        "        return\n",
        "    key = getpass(f'Enter {env_name} (input hidden): ')\n",
        "    if not key or not key.strip():\n",
        "        raise ValueError(f'{env_name} is required for this provider.')\n",
        "    os.environ[env_name] = key.strip()\n",
        "    print(f'‚úì {env_name} captured (not printed)')\n",
        "\n",
        "if PROVIDER == 'openai':\n",
        "    ensure_key('OPENAI_API_KEY')\n",
        "elif PROVIDER == 'gemini':\n",
        "    ensure_key('GEMINI_API_KEY')\n",
        "elif PROVIDER == 'ollama':\n",
        "    print('‚úì Ollama selected (no API key needed)')\n",
        "else:\n",
        "    raise ValueError('Invalid PROVIDER. Use: openai | gemini | ollama')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Use case: generate a content pack\n",
        "Fill in the inputs below. Keep them short.\n",
        "\n",
        "Tip: For short-form video, hooks should be punchy and visual.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def llm(prompt: str) -> str:\n",
        "    prompt = prompt.strip()\n",
        "    if PROVIDER == 'openai':\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI()\n",
        "        resp = client.responses.create(\n",
        "            model=OPENAI_MODEL,\n",
        "            input=prompt\n",
        "        )\n",
        "        # Responses API returns output items; simplest: grab output_text\n",
        "        return resp.output_text\n",
        "\n",
        "    if PROVIDER == 'gemini':\n",
        "        from google import genai\n",
        "        client = genai.Client(api_key=os.environ.get('GEMINI_API_KEY'))\n",
        "        resp = client.models.generate_content(\n",
        "            model=GEMINI_MODEL,\n",
        "            contents=prompt\n",
        "        )\n",
        "        return resp.text\n",
        "\n",
        "    if PROVIDER == 'ollama':\n",
        "        url = 'http://localhost:11434/api/generate'\n",
        "        payload = {\n",
        "            'model': OLLAMA_MODEL,\n",
        "            'prompt': prompt,\n",
        "            'stream': False\n",
        "        }\n",
        "        r = requests.post(url, json=payload, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        return data.get('response', '')\n",
        "\n",
        "    raise ValueError('Invalid PROVIDER')\n",
        "\n",
        "print('‚úì LLM helper ready')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate (JSON output)\n",
        "We ask for strict JSON so you can automate downstream.\n",
        "\n",
        "If parsing fails, re-run and the prompt will force JSON again.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parse + save\n",
        "We save to `outputs/001_content_pack.json` for reuse in your video generation pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    out = llm('Reply with exactly: OK')\n",
        "    print('Model reply:', out.strip()[:50])\n",
        "    print('‚úì Connection test passed')\n",
        "except Exception as e:\n",
        "    print('‚úó Connection test failed')\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Next steps\n",
        "- Duplicate this notebook into `002_...` and swap the **Use case** section.\n",
        "- Keep the same provider/key scaffold.\n",
        "- Your short videos can show:\n",
        "  1) the hook concept\n",
        "  2) the notebook cell running\n",
        "  3) the JSON output that your pipeline uses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUDIENCE = 'busy creators and marketers'\n",
        "OFFER = 'free starter notebook that generates hooks, captions, hashtags'\n",
        "NICHE = 'agentic AI for content creation'\n",
        "TOPIC = 'Stop prompting. Start building a content system.'\n",
        "TONE = 'confident, practical, not hype'\n",
        "PLATFORM = 'TikTok'\n",
        "CTA = 'Comment NOTEBOOK for the free download'\n",
        "\n",
        "print('‚úì Inputs set')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROMPT = f\"\"\"\n",
        "You are a creator-marketer assistant.\n",
        "Generate a content pack for short-form video.\n",
        "\n",
        "Audience: {AUDIENCE}\n",
        "Offer: {OFFER}\n",
        "Niche: {NICHE}\n",
        "Topic: {TOPIC}\n",
        "Tone: {TONE}\n",
        "Platform: {PLATFORM}\n",
        "CTA: {CTA}\n",
        "\n",
        "Rules:\n",
        "- Hooks: 5 to 9 words each. Make them visual and specific.\n",
        "- Captions: 1 to 2 sentences each. Simple language.\n",
        "- Hashtags: relevant, non-spammy, avoid banned/unsafe themes.\n",
        "- Angle summary: 1 short paragraph describing what visuals to show.\n",
        "- Return STRICT JSON only. No markdown.\n",
        "\n",
        "Return JSON schema:\n",
        "{{\n",
        "  \"hooks\": [\"...\"],\n",
        "  \"captions\": [\"...\"],\n",
        "  \"hashtags\": [\"...\"],\n",
        "  \"video_angle_summary\": \"...\"\n",
        "}}\n",
        "\"\"\".strip()\n",
        "\n",
        "raw = llm(PROMPT)\n",
        "raw[:400]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def parse_json_strict(s: str) -> dict:\n",
        "    s = s.strip()\n",
        "    # Basic cleanup if the model wraps JSON in text\n",
        "    start = s.find('{')\n",
        "    end = s.rfind('}')\n",
        "    if start == -1 or end == -1:\n",
        "        raise ValueError('No JSON object found in response.')\n",
        "    return json.loads(s[start:end+1])\n",
        "\n",
        "data = parse_json_strict(raw)\n",
        "\n",
        "Path('outputs').mkdir(exist_ok=True)\n",
        "out_path = Path('outputs/001_content_pack.json')\n",
        "out_path.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding='utf-8')\n",
        "\n",
        "print('‚úì Saved:', out_path)\n",
        "print('Hooks sample:', data['hooks'][:2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ You're set up!\n",
        "\n",
        "If you saw your content pack saved above, you've successfully generated hooks, captions, hashtags, and video angles!\n",
        "\n",
        "**üëâ Next steps to scale your content:**\n",
        "\n",
        "1. **[Notebooks as Templates](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/06_notebooks_as_templates.ipynb)** ‚Üê Learn to duplicate and reuse this notebook\n",
        "2. **[What You Can Build](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/07_what_you_can_build.ipynb)** ‚Üê See more content generation ideas\n",
        "3. **[Start Here (Complete Guide)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/00_start_here_jupyter_colab_models.ipynb)** ‚Üê Full beginner guide\n",
        "\n",
        "**Want to learn more?**\n",
        "- **[Colab vs Local](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/01_google_colab_vs_local.ipynb)** ‚Üê Choose your environment\n",
        "- **[What is a Notebook?](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/02_what_is_jupyter_notebook.ipynb)** ‚Üê Learn the basics\n",
        "- **[Secure API Keys](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/ai-literacy/04_secure_api_key_handling.ipynb)** ‚Üê Handle keys safely\n",
        "\n",
        "**Or explore the full repo:**\n",
        "- **[View on GitHub](https://github.com/YOUR_USERNAME/YOUR_REPO)** ‚Üê See all notebooks\n",
        "- **[Main README](https://github.com/YOUR_USERNAME/YOUR_REPO/blob/main/README.md)** ‚Üê Full documentation\n",
        "- **[Template Scaffold](../notebooks/_template_notebook_scaffold.md)** ‚Üê Create your own notebooks\n",
        "\n",
        "---\n",
        "\n",
        "**One click. No signup required. Just open and run!** üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
